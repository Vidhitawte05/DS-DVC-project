# -*- coding: utf-8 -*-
"""Copy of DS EXP 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D0VXBAL8mRrAzXDSg3eSz-sBUJElPqKd
"""

# Dataset Preparation - Train/Test Split

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np

# Load dataset
DATA_PATH = "/content/cleaned_data - cleaned_data.csv"
df = pd.read_csv(DATA_PATH)

# Drop unnecessary columns (Unnamed, imgURL etc.)
drop_cols = [c for c in df.columns if c.startswith('Unnamed:') or 'imgurl' in c.lower()]
df = df.drop(columns=drop_cols, errors='ignore')

# Target column
target_col = 'ratings'

# Remove rows with missing target
df[target_col] = pd.to_numeric(df[target_col], errors='coerce')
df = df.dropna(subset=[target_col]).reset_index(drop=True)

# Features and target
X = df.drop(columns=[target_col])
y = df[target_col]

# Identify numeric and categorical features
numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
categorical_features = [c for c in X.columns if c not in numeric_features]

# Split into train & test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Train shape:", X_train.shape, " Test shape:", X_test.shape)
print("Numeric features:", numeric_features)
print("Categorical features:", categorical_features)

# Commented out IPython magic to ensure Python compatibility.
# %pip install mlflow

# Baseline Model Training - Regression

import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import mlflow
import mlflow.sklearn

# Helper function for RMSE
def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# Preprocessing pipelines
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # fixed
])

# Combine into ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

# Define baseline models
models = {
    "LinearRegression": LinearRegression(),
    "DecisionTree": DecisionTreeRegressor(random_state=42),
    "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
}

# Train & evaluate models with MLflow tracking
baseline_results = {}
for name, model in models.items():
    with mlflow.start_run(run_name=f"Baseline_{name}"):
        pipe = Pipeline(steps=[('preprocessor', preprocessor),
                               ('model', model)])

        pipe.fit(X_train, y_train)
        preds = pipe.predict(X_test)

        model_rmse = rmse(y_test, preds)
        model_r2 = r2_score(y_test, preds)

        baseline_results[name] = {
            "RMSE": model_rmse,
            "R2": model_r2
        }

        # Log metrics
        mlflow.log_metric("RMSE", model_rmse)
        mlflow.log_metric("R2", model_r2)

        # Log model
        mlflow.sklearn.log_model(pipe, name)


# Print results
print("Baseline Model Performance:")
for name, metrics in baseline_results.items():
    print(f"{name}: RMSE={metrics['RMSE']:.4f}, R2={metrics['R2']:.4f}")

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
import mlflow
import mlflow.sklearn

# Decision Tree - Grid Search
dt_params = {
    'model__max_depth': [3, 5, 10, None],
    'model__min_samples_split': [2, 5, 10],
    'model__min_samples_leaf': [1, 2, 4]
}

dt_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', DecisionTreeRegressor(random_state=42))
])

with mlflow.start_run(run_name="Tuned_DecisionTree"):
    dt_grid = GridSearchCV(dt_pipe, dt_params, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)
    dt_grid.fit(X_train, y_train)

    # Log best params
    mlflow.log_params(dt_grid.best_params_)

    # Evaluate tuned models
    dt_best = dt_grid.best_estimator_
    dt_preds = dt_best.predict(X_test)

    dt_rmse = rmse(y_test, dt_preds)
    dt_r2 = r2_score(y_test, dt_preds)

    tuned_results = {
        "DecisionTree_Tuned": {
            "RMSE": dt_rmse,
            "R2": dt_r2,
            "Best Params": dt_grid.best_params_
        }
    }

    # Log metrics
    mlflow.log_metric("RMSE", dt_rmse)
    mlflow.log_metric("R2", dt_r2)

    # Log model
    mlflow.sklearn.log_model(dt_best, "DecisionTree_Tuned")


# Random Forest - Randomized Search
rf_params = {
    'model__n_estimators': [100, 200, 300],
    'model__max_depth': [5, 10, 20, None],
    'model__min_samples_split': [2, 5, 10],
    'model__min_samples_leaf': [1, 2, 4],
    'model__max_features': ['sqrt', 'log2'] # Corrected 'auto' to 'sqrt' or 'log2'
}

rf_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))
])

with mlflow.start_run(run_name="Tuned_RandomForest"):
    rf_random = RandomizedSearchCV(
        rf_pipe, rf_params,
        n_iter=10, cv=5, random_state=42,
        scoring='neg_root_mean_squared_error',
        n_jobs=-1
    )
    rf_random.fit(X_train, y_train)

    # Log best params
    mlflow.log_params(rf_random.best_params_)

    # Evaluate tuned models
    rf_best = rf_random.best_estimator_
    rf_preds = rf_best.predict(X_test)

    rf_rmse = rmse(y_test, rf_preds)
    rf_r2 = r2_score(y_test, rf_preds)

    tuned_results["RandomForest_Tuned"] = {
        "RMSE": rf_rmse,
        "R2": rf_r2,
        "Best Params": rf_random.best_params_
    }

    # Log metrics
    mlflow.log_metric("RMSE", rf_rmse)
    mlflow.log_metric("R2", rf_r2)

    # Log model
    mlflow.sklearn.log_model(rf_best, "RandomForest_Tuned")


# Print results
print("\nTuned Model Performance:")
for name, metrics in tuned_results.items():
    print(f"{name}: RMSE={metrics['RMSE']:.4f}, R2={metrics['R2']:.4f}")
    print("   Best Params:", metrics["Best Params"])

from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import mlflow
import mlflow.sklearn

# ----------------------------
# XGBoost with tuning
# ----------------------------
xgb_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', XGBRegressor(
        objective='reg:squarederror',
        random_state=42,
        n_jobs=-1,
        verbosity=0
    ))
])

xgb_params = {
    'model__n_estimators': [100, 200, 500],
    'model__max_depth': [3, 5, 7],
    'model__learning_rate': [0.01, 0.05, 0.1],
    'model__subsample': [0.7, 0.9, 1.0]
}

with mlflow.start_run(run_name="Tuned_XGBoost"):
    xgb_search = RandomizedSearchCV(
        xgb_pipe, xgb_params,
        n_iter=10, cv=5, random_state=42,
        scoring='neg_root_mean_squared_error',
        n_jobs=-1, verbose=1
    )
    xgb_search.fit(X_train, y_train)

    # Log best params
    mlflow.log_params(xgb_search.best_params_)

    # Evaluate tuned models
    xgb_best = xgb_search.best_estimator_
    xgb_preds = xgb_best.predict(X_test)

    xgb_rmse = rmse(y_test, xgb_preds)
    xgb_r2 = r2_score(y_test, xgb_preds)

    boosting_results = {
        "XGBoost_Tuned": {
            "RMSE": xgb_rmse,
            "R2": xgb_r2,
            "Best Params": xgb_search.best_params_
        }
    }

    # Log metrics
    mlflow.log_metric("RMSE", xgb_rmse)
    mlflow.log_metric("R2", xgb_r2)

    # Log model
    mlflow.sklearn.log_model(xgb_best, "XGBoost_Tuned")


# ----------------------------
# LightGBM with tuning
# ----------------------------
lgb_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LGBMRegressor(
        random_state=42,
        n_jobs=-1
    ))
])

lgb_params = {
    'model__n_estimators': [200, 500, 800],
    'model__max_depth': [-1, 5, 10],
    'model__learning_rate': [0.01, 0.05, 0.1],
    'model__num_leaves': [31, 50, 100]
}

with mlflow.start_run(run_name="Tuned_LightGBM"):
    lgb_search = RandomizedSearchCV(
        lgb_pipe, lgb_params,
        n_iter=10, cv=5, random_state=42,
        scoring='neg_root_mean_squared_error',
        n_jobs=-1, verbose=1
    )
    lgb_search.fit(X_train, y_train)

    # Log best params
    mlflow.log_params(lgb_search.best_params_)

    # Evaluate tuned boosting models
    lgb_best = lgb_search.best_estimator_
    lgb_preds = lgb_best.predict(X_test)

    lgb_rmse = rmse(y_test, lgb_preds)
    lgb_r2 = r2_score(y_test, lgb_preds)

    boosting_results["LightGBM_Tuned"] = {
        "RMSE": lgb_rmse,
        "R2": lgb_r2,
        "Best Params": lgb_search.best_params_
    }

    # Log metrics
    mlflow.log_metric("RMSE", lgb_rmse)
    mlflow.log_metric("R2", lgb_r2)

    # Log model
    mlflow.sklearn.log_model(lgb_best, "LightGBM_Tuned")


# ----------------------------
# Evaluate tuned boosting models
# ----------------------------
print("\nBoosting Model Performance:")
for name, metrics in boosting_results.items():
    print(f"{name}: RMSE={metrics['RMSE']:.4f}, R2={metrics['R2']:.4f}")
    print("   Best Params:", metrics["Best Params"])

